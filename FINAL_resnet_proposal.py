# -*- coding: utf-8 -*-
"""RESNET_PROPOSAL

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beeCH0-2_bK8--FZvMEY_u0RkFame0m2
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define the dataset directory path
dataset = '/content/drive/MyDrive/NEU Metal Surface Defects Data'  # Replace with your dataset path

import torch
import torchvision
from torchvision import datasets, models, transforms
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
from torchsummary import summary

# Define image transforms
image_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),
        transforms.RandomRotation(degrees=15),
        transforms.RandomHorizontalFlip(),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'valid': transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# Set data directories
train_directory = '/content/drive/MyDrive/NEU Metal Surface Defects Data/train'  # Update with the path to your training data
valid_directory = '/content/drive/MyDrive/NEU Metal Surface Defects Data/valid'  # Update with the path to your validation data

# Batch size
batch_size = 32

# Load data
data = {
    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),
    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])
}

# Get class-to-index mapping
class_to_idx = data['train'].class_to_idx
idx_to_class = {v: k for k, v in class_to_idx.items()}

# Data sizes
train_data_size = len(data['train'])
valid_data_size = len(data['valid'])

# Create data loaders
train_data_loader = DataLoader(data['train'], batch_size=batch_size, shuffle=True)
valid_data_loader = DataLoader(data['valid'], batch_size=batch_size, shuffle=True)

# Number of classes
num_classes = len(class_to_idx)

# Load a pre-trained ResNet model
resnet = models.resnet18(pretrained=True)

# Freeze all layers except the final fully connected layer
for param in resnet.parameters():
    param.requires_grad = False

# Change the final classification layer to match the number of classes in your dataset
resnet.fc = nn.Sequential(
    nn.Linear(resnet.fc.in_features, 256),  # You can change 256 to a different number if needed
    nn.ReLU(),
    nn.Dropout(0.4),  # You can adjust the dropout rate
    nn.Linear(256, num_classes),
    nn.LogSoftmax(dim=1)
)

# Move the model to the GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
resnet = resnet.to(device)

# Print a summary of the model
summary(resnet, (3, 224, 224))

# Define loss function and optimizer
loss_func = nn.NLLLoss()
optimizer = optim.Adam(resnet.parameters())

# Training and validation functions (similar to your code)
def train_and_validate(model, loss_criterion, optimizer, epochs=25):
    '''
    Function to train and validate
    Parameters
        :param model: Model to train and validate
        :param loss_criterion: Loss Criterion to minimize
        :param optimizer: Optimizer for computing gradients
        :param epochs: Number of epochs (default=25)

    Returns
        model: Trained Model with best validation accuracy
        history: (dict object): Having training loss, accuracy and validation loss, accuracy
    '''

    start = time.time()
    history = []
    best_acc = 0.0

    for epoch in range(epochs):
        epoch_start = time.time()
        print("Epoch: {}/{}".format(epoch+1, epochs))

        # Set to training mode
        model.train()

        # Loss and Accuracy within the epoch
        train_loss = 0.0
        train_acc = 0.0

        valid_loss = 0.0
        valid_acc = 0.0

        for i, (inputs, labels) in enumerate(train_data_loader):

            inputs = inputs.to(device)
            labels = labels.to(device)

            # Clean existing gradients
            optimizer.zero_grad()

            # Forward pass - compute outputs on input data using the model
            outputs = model(inputs)

            # Compute loss
            loss = loss_criterion(outputs, labels)

            # Backpropagate the gradients
            loss.backward()

            # Update the parameters
            optimizer.step()

            # Compute the total loss for the batch and add it to train_loss
            train_loss += loss.item() * inputs.size(0)

            # Compute the accuracy
            ret, predictions = torch.max(outputs.data, 1)
            correct_counts = predictions.eq(labels.data.view_as(predictions))

            # Convert correct_counts to float and then compute the mean
            acc = torch.mean(correct_counts.type(torch.FloatTensor))

            # Compute total accuracy in the whole batch and add to train_acc
            train_acc += acc.item() * inputs.size(0)

            #print("Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}".format(i, loss.item(), acc.item()))


        # Validation - No gradient tracking needed
        with torch.no_grad():

            # Set to evaluation mode
            model.eval()

            # Validation loop
            for j, (inputs, labels) in enumerate(valid_data_loader):
                inputs = inputs.to(device)
                labels = labels.to(device)

                # Forward pass - compute outputs on input data using the model
                outputs = model(inputs)

                # Compute loss
                loss = loss_criterion(outputs, labels)

                # Compute the total loss for the batch and add it to valid_loss
                valid_loss += loss.item() * inputs.size(0)

                # Calculate validation accuracy
                ret, predictions = torch.max(outputs.data, 1)
                correct_counts = predictions.eq(labels.data.view_as(predictions))

                # Convert correct_counts to float and then compute the mean
                acc = torch.mean(correct_counts.type(torch.FloatTensor))

                # Compute total accuracy in the whole batch and add to valid_acc
                valid_acc += acc.item() * inputs.size(0)

                #print("Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}".format(j, loss.item(), acc.item()))

        # Find average training loss and training accuracy
        avg_train_loss = train_loss/train_data_size
        avg_train_acc = train_acc/train_data_size

        # Find average training loss and training accuracy
        avg_valid_loss = valid_loss/valid_data_size
        avg_valid_acc = valid_acc/valid_data_size

        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])

        epoch_end = time.time()

        print("Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \n\t\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))

        # Save if the model has best accuracy till now
        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')

    return model, history
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# Train the ResNet model
num_epochs = 2
trained_model, history = train_and_validate(resnet, loss_func, optimizer, num_epochs)

# Save history and plot curves (similar to your code)
# ...

# Prediction function (similar to your code)
def predict(model, test_image_name, k=2):
    '''
    Function to predict the class of a single test image
    Parameters
        :param model: Model to test
        :param test_image_name: Test image

    '''

    transform = image_transforms['test']

    test_image = Image.open(test_image_name).convert("RGB")
    plt.imshow(test_image)

    test_image_tensor = transform(test_image)

    if torch.cuda.is_available():
        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()
    else:
        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)

    with torch.no_grad():
        model.eval()
        # Model outputs log probabilities
        out = model(test_image_tensor)
        ps = torch.exp(out)
        topk, topclass = ps.topk(k, dim=1)
        for i in range(k):
          print("Prediction", i+1, ":", idx_to_class[topclass.numpy()[0][i]], ", Score: ", topk.numpy()[0][i])

#

# Test the ResNet model
predict(trained_model, '/content/drive/MyDrive/NEU Metal Surface Defects Data/test/Crazing/Cr_1.bmp')
#predict(trained_model, '/content/drive/MyDrive/NEU Metal Surface Defects Data/train/Inclusion/In_120.bmp')

import torch
from torch.utils.data import DataLoader
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import label_binarize
from torchvision import transforms, datasets, models
import numpy as np

# Set the directory path for the validation data
valid_directory = '/content/drive/MyDrive/NEU Metal Surface Defects Data/valid'

# Batch size
bs = 32

# Load the validation data
valid_data = datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])
valid_data_loader = DataLoader(valid_data, batch_size=bs, shuffle=False)

# Collect true labels and predicted probabilities
true_labels = []
predicted_probs = []

with torch.no_grad():
    for inputs, labels in valid_data_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = trained_model(inputs)
        probs = torch.nn.functional.softmax(outputs, dim=1)

        true_labels.extend(labels.cpu().numpy())
        predicted_probs.extend(probs.cpu().numpy())

true_labels = label_binarize(true_labels, classes=list(range(num_classes)))
predicted_probs = np.array(predicted_probs)

# Calculate AUC-ROC score
auc_roc_score = roc_auc_score(true_labels, predicted_probs, average='macro')
print(f'AUC-ROC Score: {auc_roc_score}')